# В этом занятии мы продолжим тему с проверкой гипотез, а также рассмотрим 
# случаи, когда мы не знаем, нормально ли распределены наши данные

# Автор: Алексей Замалутдинов

#-------------------------------------------------------------------------
library(dplyr)
library(ggplot2)
main_dir <- dirname(rstudioapi::getSourceEditorContext()$path) 
setwd(main_dir)
#-------------------------------------------------------------------------
# У нас остался нерассмотренным случай, когда наблюдения в 2 выборках являются зависимыми друг от друга.
# Такое может происходить, например, при сравнении действия препарата до и после приёма
# Рассмотрим такую ситуацию: у нас есть группа школьников, которая выполняет логические задачки. 
# Мы решили сравнить, влияет ли наш крутой курс на время выполнения этих заданий
# Обратите внимание, здесь мы "измеряем" каждого участника дважды. Почему это важно?
before <- c(25,23,28,29,35,31,24,24,38,26,20)
after <- c(22,25,23,22,30,27,20,19,32,25,20)
# 1) Определить нулевую и альтернативные гипотезы - различий нет / различия есть
# 2) Зафиксировать уровень значимости - 0.05
# 3) Выбрать статистику критерия - двухвыборочный t-критерий Стьюдента для зависимых выборок
# 4) На основе уровня значимости определить критическую область для статистики критерия 
#    В данном случае число степеней свободы - число участников - 1
qt(0.05/2,10)
# 5) Если расчитанная статистика попадает в критическую зону, то отвергаем нулевую гипотезу.
# T = mean(x-y) / (sd(x-y)/sqrt(n))
(tstat <- mean(before - after) / (sd(before - after)/sqrt(length(before))))

# Мы можем отвергнуть нулевую гипотезу, потому что значение статистики больше критического 
# Значит наш курс крут!
#-------------------------------------------------------------------------

# До сих пор мы обсуждали ситуации, в которых наши данные распределены нормально
# или их хотя бы много. А что если у нас мало данных и не похоже, что они нормально распределены?
# 
# На помощь приходят непараметрические тесты. Они не делают предположений о распределении 
# генеральной совокупности, поэтому они могут работать с любыми данными
# 
# Резонный вопрос: если они так круты, зачем нам использовать параметрические?
# 1) Ниже мощность тестов
# 2) Сложнее интерпретировать
#
mtcars <- datasets::mtcars
mtcars$am <- as.factor(mtcars$am)
ggplot(mtcars, aes(mpg,colour = am))+ # более-менее нормально
  geom_density()
ggplot(mtcars, aes(disp,colour = am))+ # не особо нормально
  geom_density()
#-------------------------------------------------------------------------
# На глаз, оно конечно быстрее получается, но довольно субъективно.
# Поэтому существует несколько способов для проверки нормальности распределения
# Графический - квантиль-квантиль график. Если просто, то мы сравниваем наше распределение с теоритическим нормальным.
# Чем ближе точки лежат к теоритической кривой, тем более "нормальное" распределение у нас.
qqnorm(mtcars$disp)
qqline(mtcars$disp)
# Подробнее тут
# https://habr.com/ru/articles/578754/

# Численный - тест Шапиро-Уилка.
shapiro.test(mtcars$disp)
#-------------------------------------------------------------------------
# Вернёмся к нашему примеру

(am0 <- filter(mtcars,am == 0)$disp)
(am1 <- filter(mtcars,am == 1)$disp)
# давайте используем U-критерий Манна — Уитни 
# Пойдём как обычно по пунктам
# 1) Определить нулевую и альтернативные гипотезы - величины распределены одинаково / распределение величин отличается
# 2) Зафиксировать уровень значимости - 0.05
# 3) Выбрать статистику критерия - U-критерий Манна — Уитни 
# 4) На основе уровня значимости определить критическую область для статистики критерия
length(am0)
length(am1)
# Исходя их таблицы получаем ? .Если мы получим значение меньше, то сможем отвергнуть нулевую гипотезу
# 5) Расчёт статистики
# U1 = n1n2 + n1*(n1+1)/2 - R1
# U2 = n1n2 + n2*(n2+1)/2 - R2
# где n - размер а, R - сумма рангов соответствующей выборки
# Из двух выбираем меньшую, она и будет нашим значением статистики
# Давайте посмотрим как это делается вручную. Сделаем общий список в порядке возрастания. Пометим значения из одной выборки
#     
# %71.1 %75.7 %78.7 %79.0 %95.1 %108.0 120.1 %120.3 %121.0 140.8 %145.0 146.7 %160.0 %160.0 167.6 167.6 225.0 258.0 275.8 275.8 275.8 %301.0 304.0 318.0 350.0 360.0 360.0 400.0 440.0 460.0 472.0
#   1     2      3    4     5     6      7      8     9     10     11    12     13     14     15    16    17    18    19    20   21     22     23   24     25   26    27    28    29    30     31    
R1 <-  7 + 10 + 12 + 15.5 + 15.5 + 17 + 18 + 20 + 20 + 20 + 23 + 24 + 25 + 26.5 + 26.5 + 28 + 29 + 30 + 31
R2 <-  1 + 2 + 3 + 4 + 5 + 6 + 8 + 9 + 11 + 13.5 + 13.5 + 22
(U1 <-  length(am0)*length(am1) + length(am0)*(length(am0)+1)/2 - R1)
(U2 <-  length(am0)*length(am1) + length(am1)*(length(am1)+1)/2 - R2)
# Однако в R нет прямого аналога ручному расчёту
wilcox.test(am0,am1, correct = F)

#-------------------------------------------------------------------------

# А если у нас данные распределены ненормально и наблюдения зависимы?
# Нам поможет T-критерий Вилко́ксона
# Возьмём тот же пример с логическими задачами
before <- c(25,23,28,29,35,31,24,24,38,26,20)
after <- c(22,25,23,22,30,27,20,19,32,25,20)
# 1) Определить нулевую и альтернативные гипотезы - различий нет / различия есть
# 2) Зафиксировать уровень значимости - 0.05
# 3) Выбрать статистику критерия - T-критерий Вилко́ксона
# 4) На основе уровня значимости определить критическую область для статистики критерия
#    По таблице ?
# 5) Если расчитанная статистика попадает в критическую зону, то отвергаем нулевую гипотезу.
#    Расчитаем разницу, возьмём её по модулю, расставим значения по возрастанию и присвоим ранги,
#    Статистика рассчитывается как минимальное из сумм рангов для положительных и отрицательных чисел
before - after
abs(before - after)
# 0  1  2  3   4   4  5  5  5  6  7
# 1  2  3  4  5.5 5.5 8  8  8  10 11
T_minus <- 3
T_plus <- 2 + 4 + 5.5 +5.5 +8 + 8 + 8 + 10 +11
#
wilcox.test(before,after, paired = T, correct = F)
# Ещё можно почитать тут https://medstatistic.ru/methods/methods3.html

#-------------------------------------------------------------------------

# Иногда у нас есть только качественные переменные (цвет, бренд, содержится/нет), но что-то всё равно хочется проверить. 
# Давайте проверим такую гипотезу: 
# нет различий в доле женатых/замужем между группами с одобренным и неодобренным займом
# То есть у нас две выборки со значением качественного признака

loan.train <- read.csv("loan-train.csv",sep = ";")
# Уберём NA
loan.train[loan.train == ""] <- NA
loan.train_without_na <- na.omit(loan.train)
# Изменим кодировку married
loan.train_without_na <- loan.train_without_na %>% 
  mutate(Married = if_else(Married == "Yes",1,0))
loan_accepted <- filter(loan.train_without_na, Loan_Status == "Y")$Married
loan_declined <- filter(loan.train_without_na, Loan_Status != "Y")$Married
# Для этих выборок мы можем посчитать среднее и стандартное отклонение
mean(loan_accepted) 
mean(loan_declined)
# Но что за величину мы получаем? 
# Это частота (вероятность) фактора под шифром 1 (женат/замужем)
# Кажется доля людей в браке в одобренных кредитах выше
# Однако, мы ничего не знаем о разбросе данной величины
sd(loan_accepted) 
sd(loan_declined)
# На деле стандартное отклонение заключено в узкие рамки (0 и 0.5)
# Однако нас больше интересует изменчивость среднего (вероятности)
sd(loan_accepted) / sqrt(length(loan_accepted))
sd(loan_declined) / sqrt(length(loan_declined))
# ! Внимание !
# На второй лекции мы тоже сталкивались с таким делением на квадрат разности
# На деле таким образом мы получаем стандартное отклонение среднего (а не выборки)
# Теперь у нас есть всё, чтобы рассчитать статистику критерия
# Формула та же, что и у критерия Стьюдента для 2 выборок
# (mean(x) - mean(y)) / sqrt(sd(x)^2/n(x)+sd(y)^2/n(y))
z <- (mean(loan_accepted) - mean(loan_declined)) / sqrt(sd(loan_accepted)^2/length(loan_accepted)+sd(loan_declined)^2/length(loan_declined))
z
t.test(loan_accepted,loan_declined)
# Однако, критические значения мы будем искать по стандартному нормальному распределению
# Поскольку мы работаем с дискретными величинами в выборке, то обычно значения получаются завышенными
# Для компенсации используют поправку Йейтса
# (mean(x) - mean(y) - 1/2*(1/n(x) + 1/n(y))) / sqrt(sd(x)^2/n(x)+sd(y)^2/n(y))
z_adj <- (mean(loan_accepted) - mean(loan_declined) - 1/2*(1/length(loan_accepted) + 1/length(loan_declined))) / sqrt(sd(loan_accepted)^2/length(loan_accepted)+sd(loan_declined)^2/length(loan_declined))
z_adj
# Найдём критическое значение
abs(qnorm(0.05/2)) 
z_adj>abs(qnorm(0.05/2)) 
# Значит различия в доле людей в браке всё-таки есть
#-------------------------------------------------------------------------
# Однако данный тест не очень подходит, когда мы хотим отследить 
# взаимосвязь между 2 величинами с несколькими уровнями фактора
# Здесь нам на помощь приходит критерий Хи-квадрат, 
# критические значения определяются по распределению хи-квадрат с К степенями свободы
# Если сказать простым языком, то это сумма квадратов К нормально распределённых случайных величин. 
# Проиллюстрируем:
a <- rnorm(10000)^2
b <- rnorm(10000)^2
c <- rnorm(10000)^2
d <- rnorm(10000)^2
e <- rnorm(10000)^2
a <- a 
ab <- a + b 
abc <- a + b + c 
abcd <- a + b + c + d 
abcde <- a + b + c + d + e
a <- as.data.frame(a)
ab <- as.data.frame(ab)
abc <- as.data.frame(abc)
abcd <- as.data.frame(abcd)
abcde <- as.data.frame(abcde)
ggplot() +
  geom_density(data = a, aes(a), color = "red")+
  geom_density(data = ab, aes(ab), color = "blue")+
  geom_density(data = abc, aes(abc), color = "green")+
  geom_density(data = abcd, aes(abcd), color = "orange")+
  geom_density(data = abcde, aes(abcde), color = "brown")
# 
# Для того чтобы провести тест, нам необходима таблица с количеством наблюдений в пересечениях

# Рассмотрим на примере датасета mtcars
# Мы хотим проверить, есть ли зависимость между типом коробки передач и типом двигателя.
table(mtcars$am,mtcars$vs)
# 1) Определить нулевую и альтернативные гипотезы - зависимости нет / зависимость есть
# 2) Зафиксировать уровень значимости - 0.05
# 3) Выбрать статистику критерия - критерий Хи-квадрат (критерий Пирсона)
# 4) На основе уровня значимости определить критическую область для статистики критерия
qchisq(0.95,1) # степени свободы считаются как (число колонок - 1)*(число столбцов - 1)
# 5) Если расчитанная статистика попадает в критическую зону, то отвергаем нулевую гипотезу.
#    Нам нужно расчитать сумму квадратов разниц наблюдаемых и ожидаемых значений, делённую на число ожидаемых 
#    Где взять ожидаемые?
#    Возьмём нашу исходную таблицу и посчитаем суммы строк и столбцов
#  12   7  | 19       a     b  | a + b
#  6    7  | 13       c     d  | c + d
#  --------         ---------
#  18   14   32      a+c   b+d   a+b+c+d
#    Теперь посчитаем ожидаемую таблицу
#  19*18/32   14*19/32        (a+b)(a+c)/total     (a+b)(b+d)/total  
#  13*18/32   14*13/32        (c+d)(a+c)/total     (c+d)(b+d)/total
#    В итоге получаем
#  10.6875   8.3125
#  7.3125    5.6875
# Теперь считаем статистику критерия
(chistat <- (12-10.6875)^2/10.6875 + (6-7.3125)^2/7.3125 + (7-8.3125)^2/8.3125 + (7-5.6875)^2/5.6875)
# В нашем случае получилось что мы не превысили критическое значение, 
# значит мы не можем отвергнуть предположение о независимости переменных
chisq.test(table(mtcars$am,mtcars$vs),correct=F)

# Неплохой способ визуализации такого теста
library(vcd)
mosaic(~ am + vs,
       direction = c("v", "h"),
       data = mtcars,
       shade = TRUE)
# Хорошо рассказано тут
# https://blog.skillfactory.ru/glossary/kriteriy-hi-kvadrat/?ysclid=lk26eee29i554838103
#
#-------------------------------------------------------------------------
#
# Однако, есть один нюанс. 
# Если у нас мало наблюдений и получилось так, что в одной из ячеек меньше 5 наблюдений
# В таком случае, строго говоря, мы не можем применить критерий Хи-квадрат.
# Но очень хочется ведь!
# Тогда нам приходит на помощь точный критерий Фишера
#
#  12   7  | 19       a     b  | a + b
#  6    7  | 13       c     d  | c + d
#  --------         ---------
#  18   14   32      a+c   b+d   a+b+c+d
# 
# (a + b)!(c + d)!(a + c)!(b + d)!/(a!b!c!d!n!) # вероятность получить такое или более экстремальное значение статистики
factorial(19)*factorial(18)*factorial(13)*factorial(14)/factorial(12)/factorial(6)/factorial(7)/factorial(7)/factorial(32)
# сверимся со встроенной функцией
fisher.test(table(mtcars$am,mtcars$vs), alternative="greater")
# Что-то не так, p-value не сошлось с нашим. Почему так?
# Дело в том, что для расчётов нужно посчитать такую вероятность для нескольких таблиц,
# в которых мы уменьшили наименьшее число на 1, а остальные так, чтобы суммы строк и колонок не изменились
#  13   6  | 19       a     b  | a + b
#  5    8  | 13       c     d  | c + d
#  --------         ---------
#  18   14   32      a+c   b+d   a+b+c+d

#  14   5  | 19       a     b  | a + b
#  4    9  | 13       c     d  | c + d
#  --------         ---------
#  18   14   32      a+c   b+d   a+b+c+d

#  15   4  | 19       a     b  | a + b
#  3    10  | 13       c     d  | c + d
#  --------         ---------
#  18   14   32      a+c   b+d   a+b+c+d

#  16   3  | 19       a     b  | a + b
#  2    11  | 13       c     d  | c + d
#  --------         ---------
#  18   14   32      a+c   b+d   a+b+c+d

#  17   2  | 19       a     b  | a + b
#  1    12  | 13       c     d  | c + d
#  --------         ---------
#  18   14   32      a+c   b+d   a+b+c+d

#  18   1  | 19       a     b  | a + b
#  0    13  | 13       c     d  | c + d
#  --------         ---------
#  18   14   32      a+c   b+d   a+b+c+d
factorial(19)*factorial(18)*factorial(13)*factorial(14)/factorial(12)/factorial(6)/factorial(7)/factorial(7)/factorial(32)
factorial(19)*factorial(18)*factorial(13)*factorial(14)/factorial(13)/factorial(5)/factorial(6)/factorial(8)/factorial(32)
factorial(19)*factorial(18)*factorial(13)*factorial(14)/factorial(14)/factorial(4)/factorial(5)/factorial(9)/factorial(32)
factorial(19)*factorial(18)*factorial(13)*factorial(14)/factorial(15)/factorial(3)/factorial(4)/factorial(10)/factorial(32)
factorial(19)*factorial(18)*factorial(13)*factorial(14)/factorial(16)/factorial(2)/factorial(3)/factorial(11)/factorial(32)
factorial(19)*factorial(18)*factorial(13)*factorial(14)/factorial(17)/factorial(1)/factorial(2)/factorial(12)/factorial(32)
factorial(19)*factorial(18)*factorial(13)*factorial(14)/factorial(18)/factorial(0)/factorial(1)/factorial(13)/factorial(32)
