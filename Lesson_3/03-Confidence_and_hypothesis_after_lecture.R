# Теперь мы умеем работать с распределениями, считать вероятности и определять их параметры
# В этом занятии подробнее обсудим доверительные интервалы и проверку гипотез

# Автор: Алексей Замалутдинов

#-------------------------------------------------------------------------
library(dplyr)
library(ggplot2)
main_dir <- dirname(rstudioapi::getSourceEditorContext()$path) 
setwd(main_dir)
#-------------------------------------------------------------------------
# Предположим, нас попросили провести анализ какой-то выборки. 
# Для простоты возьмём уже знакомый набор данных с озером.
Lake <- as.vector(LakeHuron)
mean(Lake)
# "Мы провели анализ и выяснили, что средний уровень озера 579 футов ..."
#
# Ничего не смущает?)
#
# Напомню, что выборка не равна генеральной совокупности; выборка составляет всего лишь часть от целого
# То есть, посчитав среднее выборки, мы не можем говорить, что это среднее всей генеральной совокупности
# Возвращаясь к озеру, у нас есть данные о его уровне за 98 лет, но это тоже своего рода выборка, 
# Мы ведь не знаем ничего о его уровне до и после нашего периода наблюдений

# Именно поэтому ввели понятие доверительных интервалов, это диапазон, 
# заданный определенным уровнем доверительной вероятности
#
# Как задаётся интервал?

d <- rnorm(10000)
d <- as.data.frame(d)
ggplot(d,aes(d)) +
  geom_density() +
  geom_vline(aes(xintercept = 0)) +
  geom_vline(aes(xintercept = 1)) +
  geom_vline(aes(xintercept = 2)) +
  geom_vline(aes(xintercept = 3)) +
  annotate(geom = "text", x = 0.5, y = 0.5, label = "34,13%")+
  annotate(geom = "text", x = 1.5, y = 0.5, label = "13,59%")+
  annotate(geom = "text", x = 2.5, y = 0.5, label = "2,14%")+
  annotate(geom = "text", x = 3.5, y = 0.5, label = "0,13%")

# Пусть у нас есть выборка из стандартного нормального распределения 
# со средним 0 и стандартным отклонением 1
# Предположим, мы хотим найти такое значение, которое будет отделять от наших данных 5%
qnorm(0.05) # 5% наших данных меньше -1.644854
# Так как нормальное распределение симметрично, то и 5% наших данных будут больше 1.644854
# Таким образом 90% данных находятся между этими значениями, и мы можем сказать, что 
# "с уверенностью 90% наши данные находится в интервале (-1.644854,1.644854)"
#-------------------------------------------------------------------------
# Давайте теперь наглядно посмотрим на этот уровень "уверенности"
# Пусть мы берём маленькую выборку из стандартного нормального распределения. Считаем среднее.
# И хотим чтобы с вероятностью 50% в доверительный интервал 
# нашего среднего попадало реальное среднее распределения

d <- rnorm(1000000)
d <- as.data.frame(d)
d1 <- rnorm(10)
d1 <- as.data.frame(d1)
alpha <-  0.5
right <- mean(d1$d1) - qnorm(alpha/2) * 1 /sqrt(10)
left <- mean(d1$d1) + qnorm(alpha/2) * 1 /sqrt(10)
ggplot() +
  geom_density(data=d,aes(d)) +
  geom_vline(aes(xintercept = 0),colour = "red") +
  geom_vline(aes(xintercept = right)) +
  geom_vline(aes(xintercept = left)) +
  geom_vline(aes(xintercept = mean(d1$d1)),colour = "green")+
  geom_point(data=d1, aes(x = d1,y=0.1))
#-------------------------------------------------------------------------
# А как вычислить доверительный интервал?
# Выведем формулу для границ интервала
# Как и в случае выше, наша величина должна находиться в заднаном диапазоне
# Назовём его (a,b)
# То есть a < Z < b, где Z наша случайная величина из стандартного нормального распределения
# Предположим, если наша величина не из него (почти наверняка), то можно к нему перейти так
# Z = (x - mean(x)) / sigma
# x - оценка среднего по выборке, mean(x) - среднее генеарльной совокупности (реальное)
# a < (x - mean(x)) / sigma / sqrt(n) < b  
# Довесок нужен sqrt(n), потому что строго говоря извлечение дисперсии из-под корня сдвигает оценку

# a * sigma /sqrt(n) < x - mean(x) < b * sigma /sqrt(n) # домножим на минус 1
# -a * sigma /sqrt(n) > -x + mean(x) > -b * sigma /sqrt(n)
# x - a * sigma /sqrt(n) > mean(x) > x - b * sigma /sqrt(n) # перепишем с привычным направлением знаков
# x - b * sigma /sqrt(n) < mean(x) < x - a * sigma /sqrt(n) 

# И вишенка на торте, откуда берутся a и b?
# Нормальное распределение симметрично, поэтому и по модулю критические значения будут одинаковы
# a у нас было левой границей, то есть с минусом, а b правой, с плюсом
# x - z(alpha/2) * sigma /sqrt(n) < mean(x) < x + z(alpha/2) * sigma /sqrt(n) 
#
# Вернёмся к нашему озеру, давайте рассчитаем 95% доверительный интервал для его среднего
alpha <- 0.05
mean(Lake) + qnorm(alpha/2) * sd(Lake) / sqrt(98) 
mean(Lake) - qnorm(alpha/2) * sd(Lake) / sqrt(98) 

# Отлично! Так стало гораздо информативнее!

#-------------------------------------------------------------------------

# Однако, есть один момент, где можно немного позанудничать.
# Строго говоря, в формуле стоит стандартное отклонение генеральной совокупности, а не выборки
# То есть то, чего мы в большинстве случаев не знаем.
# В целом всё остаётся тем же самым
# x - t(alpha/2) * sd /sqrt(n) < mean(x) < x + t(alpha/2) * sd /sqrt(n)

# В связи с этим, значения статистики немного меняются и подчиняются распределению Стьюдента
# От нормального оно отличается более широкими хвостами, оно также стремится к 0, но медленее
t <-  rt(100000,97)
t <- as.data.frame(t)
ggplot()+
  geom_density(data = d,aes(d))+
  geom_density(data = t,aes(t),colour = "#ff0000")
# 
# Единственный параметр распределения, число степеней свободы
# Их число на 1 меньше, чем у нас есть наблюдений в выборке.
# Как это объяснить?
# Если у нас есть среднее и 10 наблюдений, то используя 9 мы можем рассчитать десятое
# 
# Таким образом, десятое наблюдение не свободно, так как оно зависит от среднего и остальных 9
# Ещё примеры тут https://blog.minitab.com/en/statistics-and-quality-data-analysis/what-are-degrees-of-freedom-in-statistics

# А теперь снова рассчитаем доверительные интервалы для озера

mean(Lake) + qt(alpha/2,df=97) * sd(Lake) / sqrt(98) 
mean(Lake) - qt(alpha/2,df=97) * sd(Lake) / sqrt(98) 

# Есть отличия?

#-------------------------------------------------------------------------
# 
# Окей, перейдём наконец к проверке гипотез
# 
# В самом простом случае мы хотим сравнить между собой два воздействия: 
# лекарство и плацебо, два разных вида оформления сайта и тд.
# Конечно, иногда можно сказать, что "И так видно", "Это очевидно" и тп., 
# но в таком случае мы вообще не контролируем наш риск ошибиться. 
iris_2 <- filter(iris, Species != "versicolor")
ggplot(iris_2, aes(Sepal.Width,color = Species))+
  geom_density()
# Нулевая гипотеза - эффект который мы принимаем за базис, например, плацебо или старую версию сайта
# Она верна, пока мы не доказали обратное
# Альтернативная - лекарство или новый сайт

# Однако, чтобы избежать принятия неверного решения мы задаём уровень значимости, например, 5%, 
# чтобы отсечь не такие редкие (а значит вполне возможно случайные) события
# Он является уровнем ошибки или риском отвергнуть нулевую гипотезу, когда она верна.
#
# Теперь осталось решить, как мы поймём, что мы вышли или не вышли за этот порог?
#
# Для этого нам нужен статистический критерий, например, t-критерий Стьюдента
# 
# Таким образом уровень значимости и критерий задают 
# правила принятия/не принятия нулевой гипотезы. 
# Подытожим алгоритм:
# 1) Определить нулевую и альтернативные гипотезы
# 2) Зафиксировать уровень значимости
# 3) Выбрать статистический критерий
# 4) На основе уровня значимости определить критическую область для статистики критерия
# 5) Если рассчитанная статистика попадает в критическую зону, то отвергаем нулевую гипотезу.
#    Иначе, нулевая гипотеза верна


# Разберём всё на примере с ирисами:
# Для упрощения будем считать, что у нас есть основная большая популяция ирисов (setosa),
# и мы хотим узнать отличается от неё virginica или нет
# 1) 
# 2) 5% уровень значимости
# 3) Будем использовать t-критерий, потому что мы не знаем истинное стандартное отклонение
# 4) Рассчитаем для двухстороннего теста
qt(0.05/2,49)
#    Значит, если статистика критерия будет внутри (-2.009575, 2.009575), то нулевая 
#    гипотеза верна
# 5) Считаем статистику
# (mean(x) - mean(setosa)) / (sd / sqrt(n))
#
setosa <- filter(iris_2, Species == "setosa")$Sepal.Width
virginica <- filter(iris_2, Species == "virginica")$Sepal.Width
(mean(virginica) - mean(setosa)) / (sd(virginica)/sqrt(50))
# Отлично, вот мы и сделали наш первый тест!
t.test(virginica,mu=mean(setosa))
#-------------------------------------------------------------------------
# 
# И снова время для занудства. В прошлом тесте мы приняли за базис одну из популяций
# Однако, это не совсем верно. Мы часто работаем с выборками, где нам доподлинно 
# неизвестно распределение генеральной совокупности, а значит мы используем выборочную дисперсию
# 
var(setosa)
var(virginica)
# Далее есть два варианта статистических тестов:
# 1) Предполагаем, что дисперсии выборок равны. В реальности применимость такого теста
#    ограничена, поэтому мы не будем его рассматривать. Если очень интересно
#    https://ru.wikipedia.org/wiki/T-критерий_Стьюдента
# 2) Более реалистичный сценарий, когда дисперсии выборок не равны.
#    В этом случае статистика критерия расчитывается вот так:
#    T = (mean(x) - mean(y)) / sqrt(sd(x)^2/n(x)+sd(y)^2/n(y))
#    Для учёта степеней двух выборок используют довольно хитрую формулу
#    https://en.wikipedia.org/wiki/Student%27s_t-test
#    https://ru.wikipedia.org/wiki/T-критерий_Уэлча
#
# Давайте закрепим полученные знания на примере с ирисами
# 1) 
# 2) 5% уровень значимости
# 3) Будем использовать двухвыборочный t-критерий, потому что мы не знаем истинное стандартное отклонение и они разные
# Рассчитаем число степеней свободы

# 4) Рассчитаем для двухстороннего теста
df <- 95.547
qt(0.05/2,df)
#    Значит, если статистика критерия будет внутри (-1.985104, 1.985104), то нулевая 
#    гипотеза верна
# 5) Считаем статистику
# (mean(x) - mean(y)) / sqrt(sd(x)^2/n(x)+sd(y)^2/n(y))
#

(mean(setosa) - mean(virginica)) / sqrt(sd(setosa)**2/length(setosa) + sd(virginica)**2/length(virginica))

setosa <- filter(iris_2, Species == "setosa")$Sepal.Width
virginica <- filter(iris_2, Species == "virginica")$Sepal.Width
t.test(setosa,virginica)
#
#-------------------------------------------------------------------------
# Отлично, мы разобраслись с несколькими тестами, теперь обсудим ошибки
# С ошибкой первого рода мы уже познакомились, 
# это уровень значимости теста, который мы сами задали. 
# Ошибка первого рода - вероятность отвергнуть нулевую гипотезу, когда она верна (alpha)

# Обсудим ошибки второго рода, это, наоборот, 
# вероятность сохранить нулевую гипотезу, когда она ложна (beta)
# 
# Сразу рассмотрим пример, чтобы было понятнее
# Предположим, что мы хотим штрафовать водителей, которые превышают скорость 120 км/ч
# Известно, что дисперсия измерения скорости равна 4. Мы делаем 3 измерения. 
# Определим порог, который позволит нам штрафовать тех, кто точно нарушил, с уровнем значимости 5%
qt(0.05,Inf) # критический уровень для статистики
120 + -(qt(0.05,Inf))*sqrt(4)/sqrt(3)          # x + t(alpha/2) * sd /sqrt(n)
# 121.8993 км/ч порог, при котором мы штрафуем не более 5% невиновных
# 
# Теперь перейдём к ошибке второго рода
# Посмотрим на график, чтобы обсуждать на готовом примере
t1 <- rnorm(10000,120,sqrt(4)/sqrt(3))
t1 <- as.data.frame(t1)
t2 <- rnorm(10000,123,sqrt(4)/sqrt(3))
t2 <- as.data.frame(t2)
ggplot()+
  geom_density(data = t1,aes(t1))+
  geom_density(data = t2,aes(t2),colour = "#ff0000") +
  geom_vline(aes(xintercept = 120)) +
  geom_vline(aes(xintercept = 121.8993))+
  annotate(geom = "text", x = 123, y = 0.005, label = "Штраф")+
  annotate(geom = "text", x = 121, y = 0.005, label = "Нет штрафа")
# Зона от 120 до 121.8993 является потенциально нештрафуемой
# То есть нарушение есть (превышено 120 км/ч), но наказания нет (ниже 121.8993)
# Это и есть наглядный пример ошибки второго рода.
# Рассчитаем, какова ошибка в процентах?
pnorm(121.8993,123,sqrt(4)/sqrt(3)) - pnorm(120,123,sqrt(4)/sqrt(3))
# 
# Исходник примера тут
# https://en.wikipedia.org/wiki/Type_I_and_type_II_errors#Vehicle_speed_measuring
#
# Ещё существует понятие мощность теста - Вероятность отклонить неверную нулевую гипотезу
# 1 - beta
#
1 - (pnorm(121.8993,123,sqrt(4)/sqrt(3)) - pnorm(120,123,sqrt(4)/sqrt(3)))
#-------------------------------------------------------------------------
# Последний вопрос на сегодня
# Какой размер выборки нам нужен чтобы детектировать эффект?
# (mean(x) - mean(y)) / sqrt(sd(x)^2/n(x)+sd(y)^2/n(y))
# Если переписать это выражение на бумаге, то станет более очевидно, 
# что чем больше размеры выборок, тем больше статистика критерия, 
# а значит больше шанс зафиксировать различия
# Но ресурсы зачастую ограничены, поэтому надо сделать минимум усилий с максимумом эффекта

# Расчёт делают по такой формуле
# MDE (Minimum Detectable Effect) / sqrt((sd(x)^2+sd(y)^2)/n(x=y)) >= z(alpha) + z(beta)
# Отсюда:
# n >= ((z(alpha) + z(beta))/MDE)^2 * (sd(x)^2+sd(y)^2)

# Пример:
# Пусть у нас есть два лекарства, с одним пациент выздоравливает за 8 дней, 
# а с другим (нашим) за 6 дней. Стандартное отклонение 1 день
# Альфа = 0.05
# Бета = 0.1
# Эффект = 2 дня
((qt(0.05,Inf) + qt(0.1,Inf))/2)^2 * 2
# Взглянем на ситуацию на графике
t1 <- rnorm(10000,8,1)
t1 <- as.data.frame(t1)
t2 <- rnorm(10000,6,1)
t2 <- as.data.frame(t2)
ggplot()+
  geom_density(data = t1,aes(t1))+
  geom_density(data = t2,aes(t2),colour = "#ff0000")
#
# Немного подробнее в начале этой статьи
# https://habr.com/ru/companies/lamoda/articles/707816/

