Fisher_stat1 <- factorial(3) * factorial(11) * factorial(10) * factorial(4) / factorial(2) / factirial(1) / factorial(8) / factorial(3) / factorial(28)
# Выбираем точный критерий Фишера, т.к. число наблюдений в <5.
#    Возьмём нашу исходную таблицу и посчитаем суммы строк и столбцов
#  2   1  | 3       a     b  | a + b
#  8    3  | 11       c     d  | c + d
#  --------         ---------
#  10   4   28      a+c   b+d   a+b+c+d
# (a + b)!(c + d)!(a + c)!(b + d)!/(a!b!c!d!n!) # вероятность получить такое или более экстремальное значение статистики
Fisher_stat1 <- factorial(3) * factorial(11) * factorial(10) * factorial(4) / factorial(2) / factorial(1) / factorial(8) / factorial(3) / factorial(28)
Fisher_stat2 <- factorial(3) * factorial(11) * factorial(10) * factorial(4) / factorial(3) / factorial(0) / factorial(7) / factorial(4) / factorial(28)
Fisher_stat2 <- Fisher_stat1 + Fisher_stat2
factorial(19)*factorial(18)*factorial(13)*factorial(14)/factorial(12)/factorial(6)/factorial(7)/factorial(7)/factorial(32)
factorial(19)*factorial(18)*factorial(13)*factorial(14)/factorial(13)/factorial(5)/factorial(6)/factorial(8)/factorial(32)
factorial(19)*factorial(18)*factorial(13)*factorial(14)/factorial(14)/factorial(4)/factorial(5)/factorial(9)/factorial(32)
factorial(19)*factorial(18)*factorial(13)*factorial(14)/factorial(15)/factorial(3)/factorial(4)/factorial(10)/factorial(32)
factorial(19)*factorial(18)*factorial(13)*factorial(14)/factorial(16)/factorial(2)/factorial(3)/factorial(11)/factorial(32)
factorial(19)*factorial(18)*factorial(13)*factorial(14)/factorial(17)/factorial(1)/factorial(2)/factorial(12)/factorial(32)
factorial(19)*factorial(18)*factorial(13)*factorial(14)/factorial(18)/factorial(0)/factorial(1)/factorial(13)/factorial(32)
0.1834096 + 0.07406926 + 0.01763554
# сверимся со встроенной функцией
fisher.test(table(mtcars$am,mtcars$vs), alternative="greater")
Fisher_stat2 <- Fisher_stat1 + Fisher_stat2
df <- data.frame(c(2,8),c(1,3))
fisher.test(df, alternative="greater")
p_fisher <- fisher.test(df, alternative="greater")$p.value
# Выбираем точный критерий Фишера, т.к. число наблюдений в <5.
#    Возьмём нашу исходную таблицу и посчитаем суммы строк и столбцов
#  2   1  | 3       a     b  | a + b
#  8    3  | 11       c     d  | c + d
#  --------         ---------
#  10   4   28      a+c   b+d   a+b+c+d
# (a + b)!(c + d)!(a + c)!(b + d)!/(a!b!c!d!n!) # вероятность получить такое или более экстремальное значение статистики
Fisher_stat1 <- factorial(3) * factorial(11) * factorial(10) * factorial(4) / factorial(2) / factorial(1) / factorial(8) / factorial(3) / factorial(28)
#  3   0  | 3       a     b  | a + b
#  7    4  | 11       c     d  | c + d
#  --------         ---------
#  10   4   28      a+c   b+d   a+b+c+d
Fisher_stat2 <- factorial(3) * factorial(11) * factorial(10) * factorial(4) / factorial(3) / factorial(0) / factorial(7) / factorial(4) / factorial(28)
Fisher_stat2 <- Fisher_stat1 + Fisher_stat2
df <- data.frame(c(2,8),c(1,3))
p_fisher <- fisher.test(df, alternative="greater")$p.value
FALSE
library(dplyr)
library(ggplot2)
library(boot)
main_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(main_dir)
library(devtools)
install.packages(devtools)
install.packages('devtools')
install.packages("devtools")
library(dplyr)
library(ggplot2)
library(boot)
main_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(main_dir)
library(devtools)
devtools::install_github("ProcessMiner/nlcor")
install.packages('RTools')
library(dplyr)
library(ggplot2)
library(boot)
main_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(main_dir)
library(devtools)
devtools::install_github("ProcessMiner/nlcor")
library(nlcor)
library(dplyr)
library(ggplot2)
library(boot)
main_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(main_dir)
library(devtools)
devtools::install_github("ProcessMiner/nlcor")
library(nlcor)
library(dplyr)
library(ggplot2)
library(boot)
main_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(main_dir)
library(devtools)
devtools::install_github("ProcessMiner/nlcor")
library(nlcor)
x <- rnorm(50000)
x1 <- rnorm(20)
x4 <- rnorm(200)
x <- as.data.frame(x)
x1 <- as.data.frame(x1)
x4 <- as.data.frame(x4)
ggplot() +
stat_ecdf(data = x, aes(x)) +
stat_ecdf(data = x1, aes(x1),colour = "red") +
stat_ecdf(data = x4, aes(x4),colour = "blue")
stat_fun <- function(x, idx) mean(x[idx])
boot_obj <- boot(x4$x4, R=10000, statistic=stat_fun)
boot_obj
mean(x4$x4)
sd(x4$x4)
mean(boot_obj$t)
(a <- sample(filter(iris, Species == "setosa")$Sepal.Length, size = 50, replace=T))
median(a)
stat_fun <- function(x, idx) median(x[idx])
boot_obj <- boot(filter(iris, Species == "setosa")$Sepal.Length, R=1000, statistic=stat_fun)
boot_obj
median(filter(iris, Species == "setosa")$Sepal.Length)
t <- as.data.frame(boot_obj$t)
ggplot(t, aes(V1)) +
geom_density()
shapiro.test(boot_obj$t)
boot.ci(boot_obj, R=1000, statistic=stat_fun)
stat_fun <- function(x, idx) median(x[idx])
boot_diamonds <- boot(slice_sample(diamonds, n = 1000)$price, R=1000, statistic=stat_fun)
boot_diamonds
t <- as.data.frame(boot_diamonds$t)
ggplot(t, aes(V1)) +
geom_density()
boot.ci(boot_diamonds, R=1000, statistic=stat_fun)
foo <- function(data, indices){
dt<-data[indices,]
c(
cor(dt[,1], dt[,2], method='s'),
median(dt[,1])
)
}
boot_2_metrics <- boot(filter(iris, Species == "setosa"), R=1000, statistic=foo)
boot_2_metrics
t <- as.data.frame(boot_2_metrics$t)
ggplot(t, aes(V1)) +
geom_density()
boot.ci(boot_2_metrics, R=1000, statistic=foo, index=1)
boot.ci(boot_2_metrics, R=1000, statistic=foo, index=1)
# Мы рассмотрели классические основы статистики и сегодня коснёмся
# одного из более современных способов оценки параметров и проверки гипотез
# Автор: Алексей Замалутдинов
#-------------------------------------------------------------------------
library(dplyr)
library(ggplot2)
library(boot)
main_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(main_dir)
library(devtools)
devtools::install_github("ProcessMiner/nlcor")
library(nlcor)
#-------------------------------------------------------------------------
# Обычно мы берём наши данные и предполагаем, что они подчиняются тому или иному распределению,
# это помогает нам понять как распределены наши данные и проверять гипотезы исходя из этого.
# Однако, так или иначе это является приближением и не позволяет рассчитаывать доверительный интервал,
# например, для медианы или произвольного квартиля. Что делать?
#
# Что мы делаем обычно? Исходя из нашей выборки считаем параметры,
# например, среднее и стандартное отклонение, и задаём функцию распределения с такими параметрами.
# На самом деле, нам необязательно пытаться подстроить наши данные под то или иное типовое распределение,
# ведь наши данные сами являются распределением.
# Построим график кумулятивной вероятности (от 0 до 1)
x <- rnorm(50000)
x1 <- rnorm(20)
x4 <- rnorm(200)
x <- as.data.frame(x)
x1 <- as.data.frame(x1)
x4 <- as.data.frame(x4)
ggplot() +
stat_ecdf(data = x, aes(x)) +
stat_ecdf(data = x1, aes(x1),colour = "red") +
stat_ecdf(data = x4, aes(x4),colour = "blue")
stat_fun <- function(x, idx) mean(x[idx])
boot_obj <- boot(x4$x4, R=10000, statistic=stat_fun)
boot_obj
mean(x4$x4)
sd(x4$x4)
mean(boot_obj$t)
# Что мы здесь видим? Чем больше наша выборка, тем ближе она приближается к кривой вероятности,
# созданной исходным распределением (нормальным в данном случае). Таким образом, нам не нужно
# определять исходное распределение и определять его параметры. Такая функция распределения называется
# эмпирической функцией распределения.
#
# Если наша функция распределения довольно хорошо приближается к
# оригинальному распределению то, мы можем использовать её для нашего анализа.
#
# Вернёмся к вопросу о медиане, как оценить её доверительный интервал?
# Было бы круто, если бы у нас было много таких выборок,
# мы бы посчитали медиану для каждой и рассчитали бы среднее и стандратное отклонение.
# Но у нас всего одна, что делать?
#
# Сгенерировать новые! На основе нашей выборки создадим 1000 новых выборок с повторением.
#
(a <- sample(filter(iris, Species == "setosa")$Sepal.Length, size = 50, replace=T))
median(a)
stat_fun <- function(x, idx) median(x[idx])
boot_obj <- boot(filter(iris, Species == "setosa")$Sepal.Length, R=1000, statistic=stat_fun)
boot_obj
median(filter(iris, Species == "setosa")$Sepal.Length) # медиана выборки равна 5
# Полученная 1000 медиан не очень нормально распределена
t <- as.data.frame(boot_obj$t)
ggplot(t, aes(V1)) +
geom_density()
shapiro.test(boot_obj$t)
boot.ci(boot_obj, R=1000, statistic=stat_fun)
# Здесь для нас сразу расчитывается несколько версий доверительных интервалов, рассмотрим 2 из них
# Если наши оценки медиан распределены нормально, мы можем расчитать
# доверительный интервал с критическими значениями нормального распределения
# В данном случае делается ещё поправка на смещение величины
# sample_median - bias +- se * qnorm(0.975)
# Верхняя граница тогда будет такой, как и расчитано функцией в типе Normal
5 - 0.01225 + 0.04743087 * qnorm(0.975)
# Нижняя
5 - 0.01225 - 0.04743087 * qnorm(0.975)
# Другой интересный способ оценки, это перцентиль.
# В случае, если оценка получилась ненормально распределённой, то мы можем задать доверительный интервал,
# выбросив самые экстремальные значения
# В нашем случае это 2.5% оценок с одной стороны и 2.5% с другой
stat_fun <- function(x, idx) median(x[idx])
boot_diamonds <- boot(slice_sample(diamonds, n = 1000)$price, R=1000, statistic=stat_fun)
boot_diamonds
t <- as.data.frame(boot_diamonds$t)
ggplot(t, aes(V1)) +
geom_density()
boot.ci(boot_diamonds, R=1000, statistic=stat_fun)
# А ещё мы можем считать доверительные интервалы не только для параметров зависящих от одной переменной,
# но и более, например, корреляцию. Да и сразу несколько, чтобы получилось быстрее:)
foo <- function(data, indices){
dt<-data[indices,]
c(
cor(dt[,1], dt[,2], method='s'),
median(dt[,1])
)
}
boot_2_metrics <- boot(filter(iris, Species == "setosa"), R=1000, statistic=foo)
boot_2_metrics
t <- as.data.frame(boot_2_metrics$t)
ggplot(t, aes(V1)) +
geom_density()
# Как раз случай, когда метрика распределена не очень нормально
boot.ci(boot_2_metrics, R=1000, statistic=foo, index=1)
#
#-------------------------------------------------------------------------
# Более того, бустреп позволяет нам проверять гипотезы. Если у нас есть доверительные интервалы,
# а значит и есть критические значения. Всё, что за них выходит является экстремальными значениями.
# Таким образом, у нас есть основания принять или отвергнуть наши предположения (гипотезы)
# Пример:
# Когда-то мы уже проверяли гипотезу о равенстве средних ширин лепестков двух популяций ирисов
# Давайте проверим это снова:
setosa <- filter(iris, Species == "setosa")$Sepal.Width
virginica <- filter(iris, Species == "virginica")$Sepal.Width
t.test(setosa,virginica) # различаются по т тесту
# Теперь сделаем проверку бутстрепом
mean_difference <- function(data, indices){
dt<-data[indices,]
mean_1 <- mean(dt[,1])
mean_2 <- mean(dt[,2])
mean_1 - mean_2
}
data_iris <- data.frame(setosa,virginica)
boot_test <- boot(data_iris, R=1000, statistic=mean_difference)
boot_test
t <- as.data.frame(boot_test$t)
ggplot(t, aes(V1)) +
geom_density()
boot.ci(boot_test, R=1000, statistic=mean_difference)
# Так, что мы видим
# Получается, что 95% доверительный интервал для разницы средних у нас от 0.3136 до 0.5983
# Мы же в нулевой гипотезе предполагаем, что разницы между средними нет, равна 0
# То есть 0 не находится в нашем доверительном интервале, а значит мы можем отвергнуть нулевую гипотезу
pnorm(0,0.454+bias,0.07263405)*2 # умножаем на 2, чтобы учесть двухстороннесть оценки
# Так, что мы видим
# Получается, что 95% доверительный интервал для разницы средних у нас от 0.3136 до 0.5983
# Мы же в нулевой гипотезе предполагаем, что разницы между средними нет, равна 0
# То есть 0 не находится в нашем доверительном интервале, а значит мы можем отвергнуть нулевую гипотезу
pnorm(0,0.454+-0.001712,0.07002185)*2 # умножаем на 2, чтобы учесть двухстороннесть оценки
setosa <- filter(iris, Species == "setosa")$Sepal.Width
virginica <- filter(iris, Species == "virginica")$Sepal.Width
real_diff <- mean(setosa) - mean(virginica)
real_diff
setosa_virginica <- c(setosa,virginica)
perm_fun <- function(x, nA, nB) {
n <- nA+nB
idx_b <- sample(1:n, nB)
idx_a <- setdiff(1:n, idx_b)
mean_diff <- mean(x[idx_b]) - mean(x[idx_a])
return(mean_diff)
}
# Проверим её
perm_fun(setosa_virginica,50,50)
# Теперь повторим 10000
i = 1
# Проверим её
perm_fun(setosa_virginica,50,50)
# Проверим её
perm_fun(setosa_virginica,50,50)
result <- c()
for (i in seq(1:10000)) {
result[i] <- perm_fun(setosa_virginica,50,50)
}
# А это наше p value. Вероятность получить группы более разные чем у нас есть.
mean(result > real_diff)
result <- as.data.frame(result)
ggplot(result, aes(result)) +
geom_density(
)
# А это наше p value. Вероятность получить группы более разные чем у нас есть.
mean(result > real_diff)
for (i in seq(1:100000000)) {
result[i] <- perm_fun(setosa_virginica,50,50)
}
gc()
result <- c()
for (i in seq(1:100000000)) {
result[i] <- perm_fun(setosa_virginica,50,50)
}
perm_fun <- function(x, nA, nB) {
n <- nA+nB
idx_b <- sample(1:n, nB)
idx_a <- setdiff(1:n, idx_b)
mean_diff <- mean(x[idx_b]) - mean(x[idx_a])
return(mean_diff)
}
i = 1
result <- c()
for (i in seq(1:100000000)) {
result[i] <- perm_fun(setosa_virginica,50,50)
}
setosa <- filter(iris, Species == "setosa")$Sepal.Width
i = 1
result <- c()
for (i in seq(1:100000000)) {
result[i] <- perm_fun(setosa_virginica,50,50)
}
# Идея довольно логичная. Если мы предполагаем, что наборы данных не отличаются, то и в случае
# их перемешивания между собой, они тоже не будут отличаться.
# Алгоритм:
# 1) Определить нулевую гипотезу
# 2) Расчитать параметр для исходных данных (например, разницу между средними)
# 3) Объединить данные и случайно набрать группы заново (без повторений)
# 4) Расчитать параметр для новых наборов
# 5) Повторить п. 3-4 много раз (10000)
# 6) Сранить реальное значение с полученным распределением
# Вернёмся к нашим ирисам и попробуем на них
setosa <- filter(iris, Species == "setosa")$Sepal.Width
# Мы рассмотрели классические основы статистики и сегодня коснёмся
# одного из более современных способов оценки параметров и проверки гипотез
# Автор: Алексей Замалутдинов
#-------------------------------------------------------------------------
library(dplyr)
library(ggplot2)
library(boot)
main_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(main_dir)
library(devtools)
devtools::install_github("ProcessMiner/nlcor")
library(nlcor)
#-------------------------------------------------------------------------
# Обычно мы берём наши данные и предполагаем, что они подчиняются тому или иному распределению,
# это помогает нам понять как распределены наши данные и проверять гипотезы исходя из этого.
# Однако, так или иначе это является приближением и не позволяет рассчитаывать доверительный интервал,
# например, для медианы или произвольного квартиля. Что делать?
#
# Что мы делаем обычно? Исходя из нашей выборки считаем параметры,
# например, среднее и стандартное отклонение, и задаём функцию распределения с такими параметрами.
# На самом деле, нам необязательно пытаться подстроить наши данные под то или иное типовое распределение,
# ведь наши данные сами являются распределением.
# Построим график кумулятивной вероятности (от 0 до 1)
x <- rnorm(50000)
x1 <- rnorm(20)
x4 <- rnorm(200)
x <- as.data.frame(x)
x1 <- as.data.frame(x1)
x4 <- as.data.frame(x4)
ggplot() +
stat_ecdf(data = x, aes(x)) +
stat_ecdf(data = x1, aes(x1),colour = "red") +
stat_ecdf(data = x4, aes(x4),colour = "blue")
stat_fun <- function(x, idx) mean(x[idx])
boot_obj <- boot(x4$x4, R=10000, statistic=stat_fun)
boot_obj
mean(x4$x4)
sd(x4$x4)
mean(boot_obj$t)
# Что мы здесь видим? Чем больше наша выборка, тем ближе она приближается к кривой вероятности,
# созданной исходным распределением (нормальным в данном случае). Таким образом, нам не нужно
# определять исходное распределение и определять его параметры. Такая функция распределения называется
# эмпирической функцией распределения.
#
# Если наша функция распределения довольно хорошо приближается к
# оригинальному распределению то, мы можем использовать её для нашего анализа.
#
# Вернёмся к вопросу о медиане, как оценить её доверительный интервал?
# Было бы круто, если бы у нас было много таких выборок,
# мы бы посчитали медиану для каждой и рассчитали бы среднее и стандратное отклонение.
# Но у нас всего одна, что делать?
#
# Сгенерировать новые! На основе нашей выборки создадим 1000 новых выборок с повторением.
#
(a <- sample(filter(iris, Species == "setosa")$Sepal.Length, size = 50, replace=T))
median(a)
stat_fun <- function(x, idx) median(x[idx])
boot_obj <- boot(filter(iris, Species == "setosa")$Sepal.Length, R=1000, statistic=stat_fun)
boot_obj
median(filter(iris, Species == "setosa")$Sepal.Length) # медиана выборки равна 5
# Полученная 1000 медиан не очень нормально распределена
t <- as.data.frame(boot_obj$t)
ggplot(t, aes(V1)) +
geom_density()
shapiro.test(boot_obj$t)
boot.ci(boot_obj, R=1000, statistic=stat_fun)
# Здесь для нас сразу расчитывается несколько версий доверительных интервалов, рассмотрим 2 из них
# Если наши оценки медиан распределены нормально, мы можем расчитать
# доверительный интервал с критическими значениями нормального распределения
# В данном случае делается ещё поправка на смещение величины
# sample_median - bias +- se * qnorm(0.975)
# Верхняя граница тогда будет такой, как и расчитано функцией в типе Normal
5 - 0.01225 + 0.04743087 * qnorm(0.975)
# Нижняя
5 - 0.01225 - 0.04743087 * qnorm(0.975)
# Другой интересный способ оценки, это перцентиль.
# В случае, если оценка получилась ненормально распределённой, то мы можем задать доверительный интервал,
# выбросив самые экстремальные значения
# В нашем случае это 2.5% оценок с одной стороны и 2.5% с другой
stat_fun <- function(x, idx) median(x[idx])
boot_diamonds <- boot(slice_sample(diamonds, n = 1000)$price, R=1000, statistic=stat_fun)
boot_diamonds
t <- as.data.frame(boot_diamonds$t)
ggplot(t, aes(V1)) +
geom_density()
boot.ci(boot_diamonds, R=1000, statistic=stat_fun)
# А ещё мы можем считать доверительные интервалы не только для параметров зависящих от одной переменной,
# но и более, например, корреляцию. Да и сразу несколько, чтобы получилось быстрее:)
foo <- function(data, indices){
dt<-data[indices,]
c(
cor(dt[,1], dt[,2], method='s'),
median(dt[,1])
)
}
boot_2_metrics <- boot(filter(iris, Species == "setosa"), R=1000, statistic=foo)
boot_2_metrics
t <- as.data.frame(boot_2_metrics$t)
ggplot(t, aes(V1)) +
geom_density()
# Как раз случай, когда метрика распределена не очень нормально
boot.ci(boot_2_metrics, R=1000, statistic=foo, index=1)
#
#-------------------------------------------------------------------------
# Более того, бустреп позволяет нам проверять гипотезы. Если у нас есть доверительные интервалы,
# а значит и есть критические значения. Всё, что за них выходит является экстремальными значениями.
# Таким образом, у нас есть основания принять или отвергнуть наши предположения (гипотезы)
# Пример:
# Когда-то мы уже проверяли гипотезу о равенстве средних ширин лепестков двух популяций ирисов
# Давайте проверим это снова:
setosa <- filter(iris, Species == "setosa")$Sepal.Width
virginica <- filter(iris, Species == "virginica")$Sepal.Width
t.test(setosa,virginica) # различаются по т тесту
# Теперь сделаем проверку бутстрепом
mean_difference <- function(data, indices){
dt<-data[indices,]
mean_1 <- mean(dt[,1])
mean_2 <- mean(dt[,2])
mean_1 - mean_2
}
data_iris <- data.frame(setosa,virginica)
boot_test <- boot(data_iris, R=1000, statistic=mean_difference)
boot_test
t <- as.data.frame(boot_test$t)
ggplot(t, aes(V1)) +
geom_density()
boot.ci(boot_test, R=1000, statistic=mean_difference)
# Идея довольно логичная. Если мы предполагаем, что наборы данных не отличаются, то и в случае
# их перемешивания между собой, они тоже не будут отличаться.
# Алгоритм:
# 1) Определить нулевую гипотезу
# 2) Расчитать параметр для исходных данных (например, разницу между средними)
# 3) Объединить данные и случайно набрать группы заново (без повторений)
# 4) Расчитать параметр для новых наборов
# 5) Повторить п. 3-4 много раз (10000)
# 6) Сранить реальное значение с полученным распределением
# Вернёмся к нашим ирисам и попробуем на них
setosa <- filter(iris, Species == "setosa")$Sepal.Width
virginica <- filter(iris, Species == "virginica")$Sepal.Width
# Определим разницу
real_diff <- mean(setosa) - mean(virginica)
real_diff
# Объединим данные
setosa_virginica <- c(setosa,virginica)
# Зададим функцию, которая будет перемешивать наши данные и считать разницу
perm_fun <- function(x, nA, nB) {
n <- nA+nB
idx_b <- sample(1:n, nB)
idx_a <- setdiff(1:n, idx_b)
mean_diff <- mean(x[idx_b]) - mean(x[idx_a])
return(mean_diff)
}
i = 1
result <- c()
for (i in seq(1:100000000)) {
result[i] <- perm_fun(setosa_virginica,50,50)
}
result <- as.data.frame(result)
ggplot(result, aes(result)) +
geom_density()
# А это наше p value. Вероятность получить группы более разные чем у нас есть.
mean(result > real_diff)
result <- c()
for (i in seq(1:10000000)) {
result[i] <- perm_fun(setosa_virginica,50,50)
}
result <- as.data.frame(result)
ggplot(result, aes(result)) +
geom_density()
# А это наше p value. Вероятность получить группы более разные чем у нас есть.
mean(result > real_diff)
# Как и всегда, есть более автоматизированный вариант анализа
iris_2 <- filter(iris, Species != "versicolor")
library(coin)
oneway_test(Sepal.Width ~ Species, data = iris_2,distribution=approximate(nresample=10000))
